```
          ______ _____ 
    /\   |  ____|_   _|
   /  \  | |__    | |  
  / /\ \ |  __|   | |  
 / ____ \| |____ _| |_ 
/_/    \_\______|_____|

```
使用自编码器进行缺失插补

Griswold1999.csv不含有多态
tnt建树
1. settings->memory->max tree 修改保存的最大树的数量
2. analyze->suboptimal 修改距最佳得分的树的保留空间

实验流程设计：
1. 在pycharm中使用缺失插补方法，对缺失数据集进行处理
2. 在tnt中建树，比较不同建树结果与论文树的RF，co distance距离
3. 在R中使用treespace，画出不同树的MSD散点图，比较不同建树结果与论文树的treeVec,nNodes距离。

实验记录：  
2020-07-17  
knn明显耗时最长，em算法在iris,wine上效果比随机插补还差，mice和ii算法在许多数据集上都表现出最好的效果。

2020-07-18  
速度最慢的应该是mice. mida和gain在一些数据集上似乎不能正常使用，最好做实验需要对照组包括最差的em，随机和均值（古生物代表插补），深度学习的mida和gain，以及最好的ii和mice

2020-07-19  
mida在一些数据集上无法得到插补结果，在cancer，banknote等相对较大的数据集上，缺失稍多就不能得到结果，这似乎是dae的缺陷
2020-07-21  
对缺失的非随机插补，不仅应该包括当前找到的随机缺失模式，至少还应该包括指定特征的缺失，指定物种的缺失，或者包括特殊小方块内的到缺失

2020-07-23  
在block上部分情况，部分mida效果更好  

2020-08-07  
初步看在一些uci数据集上，自编码器都有一些效果的提升，
现在准备做的是初始插补方法ii和mice。自编码器是否堆叠，是否加入resNet结构
对于对比方法要看一下论文gain里面提出这个方法。
#TODO list
1. ~~添加模型是否stocked，是否加入resNet~~   使用partial
2. 证明是否用交叉熵效果更好，# todo 加速需要做修改
3. 看论文gain，找到该算法的优点
4. ~~看现在方法能不能上gpu 速度太慢了，之后消融实验不然会很慢~~   ，数据集太小用gpu好像更慢

